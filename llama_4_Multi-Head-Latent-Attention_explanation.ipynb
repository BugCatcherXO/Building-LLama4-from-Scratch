{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285636e9",
   "metadata": {},
   "source": [
    "# üöÄ Self-Attention explicado con un ejemplo\n",
    "\n",
    "Este README explica **c√≥mo funciona el mecanismo de atenci√≥n** en los Transformers (el coraz√≥n de los LLMs como GPT, LLaMA, etc.), usando la frase:\n",
    "\n",
    "> **\"The dog ran quickly\"**\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 1. Contexto: ¬øQu√© es la atenci√≥n en un LLM?\n",
    "\n",
    "En un **Large Language Model (LLM)**, cada palabra (token) no se procesa de manera aislada, sino que construye su significado **teniendo en cuenta el contexto** de las dem√°s.\n",
    "\n",
    "El mecanismo que hace posible esto es la **Self-Attention**:\n",
    "\n",
    "- Cada token genera **tres vectores**:\n",
    "  - **Query (Q)** ‚Üí lo que busca.\n",
    "  - **Key (K)** ‚Üí lo que ofrece.\n",
    "  - **Value (V)** ‚Üí la informaci√≥n que aporta.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 2. El ejemplo: \"The dog ran quickly\"\n",
    "\n",
    "Supongamos que estamos procesando la palabra **\"quickly\"**.  \n",
    "Queremos saber: **¬øqu√© tokens influyen en el significado de \"quickly\"?**\n",
    "\n",
    "### Vectores iniciales (ejemplo simplificado en 3 dimensiones):\n",
    "\n",
    "- **Query (quickly)**:  \n",
    "  \\[\n",
    "  Q_{quickly} = [0.22, 0.64, 0.73]\n",
    "  \\]\n",
    "\n",
    "- **Key (dog)**:  \n",
    "  \\[\n",
    "  K_{dog} = [0.54, 0.36, 0.74]\n",
    "  \\]\n",
    "\n",
    "- **Value (dog)**:  \n",
    "  \\[\n",
    "  V_{dog} = [0.12, 0.84, 0.51]\n",
    "  \\]\n",
    "\n",
    "- **Value (quickly)**:  \n",
    "  \\[\n",
    "  V_{quickly} = [0.62, 0.24, 0.33]\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 3. Paso 1: Similaridad Query‚ÄìKey\n",
    "\n",
    "Calculamos el **producto punto** entre el Query de \"quickly\" y los Keys de otros tokens:\n",
    "\n",
    "\\[\n",
    "score(dog, quickly) = Q_{quickly} \\cdot K_{dog}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= (0.22)(0.54) + (0.64)(0.36) + (0.73)(0.74)\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= 0.1188 + 0.2304 + 0.5402 \\approx 0.889\n",
    "\\]\n",
    "\n",
    "> Este n√∫mero nos dice **qu√© tanto \"quickly\" presta atenci√≥n a \"dog\"**.\n",
    "\n",
    "(En la pr√°ctica se hace con todos los tokens: \"the\", \"dog\", \"ran\", \"quickly\"...).\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 4. Paso 2: Softmax ‚Üí Pesos de Atenci√≥n\n",
    "\n",
    "Convertimos estos scores en **pesos normalizados**:\n",
    "\n",
    "Ejemplo con solo *dog* y *quickly* (suponiendo un score para quickly ‚âà 1.2):\n",
    "\n",
    "\\[\n",
    "\\alpha_{dog} = \\frac{e^{0.889}}{e^{0.889} + e^{1.2}} \\approx 0.42\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\alpha_{quickly} = \\frac{e^{1.2}}{e^{0.889} + e^{1.2}} \\approx 0.58\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 5. Paso 3: Combinaci√≥n de Values\n",
    "\n",
    "El **output de \"quickly\"** es la **suma ponderada de los Values**:\n",
    "\n",
    "\\[\n",
    "output(quickly) = \\alpha_{dog} \\cdot V_{dog} + \\alpha_{quickly} \\cdot V_{quickly}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= 0.42 \\cdot [0.12, 0.84, 0.51] + 0.58 \\cdot [0.62, 0.24, 0.33]\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= [0.41, 0.49, 0.41] \\ (\\text{aprox})\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 6. Interpretaci√≥n conceptual\n",
    "\n",
    "- **Cada token tiene un √∫nico Value**, no uno distinto para cada otro token.  \n",
    "- Lo que cambia es el **peso con el que ese Value se combina**, seg√∫n la similitud Query‚ÄìKey.  \n",
    "- El resultado es un **nuevo vector sem√°ntico** para \"quickly\", que ya no es solo su embedding original, sino una **mezcla contextualizada** de informaci√≥n de toda la frase.  \n",
    "\n",
    "---\n",
    "\n",
    "## üìå 7. Visualizaci√≥n mental\n",
    "\n",
    "Piensa en una fiesta üéâ:\n",
    "\n",
    "- Cada persona tiene un **cartel en la frente** (**Key**) con lo que representa (‚Äús√© de perros‚Äù, ‚Äúsoy un verbo de acci√≥n‚Äù).  \n",
    "- Cada persona tambi√©n tiene un **inter√©s** (**Query**) de lo que busca (‚Äúquiero encontrar un verbo con el que encaje‚Äù).  \n",
    "- Cuando encuentran un match (Query ‚Üî Key), se escuchan con m√°s o menos atenci√≥n.  \n",
    "- Lo que cada uno aporta a la conversaci√≥n es su **Value**.  \n",
    "- El resultado es que cada persona se lleva un **nuevo resumen contextual** de la fiesta.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå 8. Conclusi√≥n\n",
    "\n",
    "- **Query + Key = cu√°nto caso hago a otro token.**  \n",
    "- **Pesos (softmax) = con qu√© fuerza escucho a cada token.**  \n",
    "- **Values = lo que cada token aporta a la mezcla.**  \n",
    "- **Output = nuevo vector contextualizado**, usado en capas posteriores para finalmente **predecir el siguiente token**.\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
