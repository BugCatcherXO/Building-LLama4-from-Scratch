{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285636e9",
   "metadata": {},
   "source": [
    "# ðŸš€ Self-Attention explained with an example\n",
    "\n",
    "This file explains **how the attention mechanism works** in Transformers (the heart of LLMs like GPT, LLaMA, etc.), using the sentence:\n",
    "\n",
    "> **\"The dog ran quickly\"**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Context: What is attention in an LLM?\n",
    "\n",
    "In a **Large Language Model (LLM)**, each word (token) is not processed in isolation, but instead builds its meaning **by taking into account the context** of the others.\n",
    "\n",
    "The mechanism that makes this possible is **Self-Attention**:\n",
    "\n",
    "- Each token generates **three vectors**:\n",
    "  - **Query (Q)** â†’ what it looks for.\n",
    "  - **Key (K)** â†’ what it offers.\n",
    "  - **Value (V)** â†’ the information it provides.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. The example: \"The dog ran quickly\"\n",
    "\n",
    "Letâ€™s suppose we are processing the word **\"quickly\"**.  \n",
    "We want to know: **which tokens influence the meaning of \"quickly\"?**\n",
    "\n",
    "### Initial vectors (simplified example in 3 dimensions):\n",
    "\n",
    "- **Query (quickly)**:  \n",
    "  \\[\n",
    "  Q_{quickly} = [0.22, 0.64, 0.73]\n",
    "  \\]\n",
    "\n",
    "- **Key (dog)**:  \n",
    "  \\[\n",
    "  K_{dog} = [0.54, 0.36, 0.74]\n",
    "  \\]\n",
    "\n",
    "- **Value (dog)**:  \n",
    "  \\[\n",
    "  V_{dog} = [0.12, 0.84, 0.51]\n",
    "  \\]\n",
    "\n",
    "- **Value (quickly)**:  \n",
    "  \\[\n",
    "  V_{quickly} = [0.62, 0.24, 0.33]\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Step 1: Queryâ€“Key similarity\n",
    "\n",
    "We calculate the **dot product** between the Query of \"quickly\" and the Keys of other tokens:\n",
    "\n",
    "\\[\n",
    "score(dog, quickly) = Q_{quickly} \\cdot K_{dog}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= (0.22)(0.54) + (0.64)(0.36) + (0.73)(0.74)\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= 0.1188 + 0.2304 + 0.5402 \\approx 0.889\n",
    "\\]\n",
    "\n",
    "> This number tells us **how much \"quickly\" pays attention to \"dog\"**.\n",
    "\n",
    "(In practice this is done with all tokens: \"the\", \"dog\", \"ran\", \"quickly\"...).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Step 2: Softmax â†’ Attention Weights\n",
    "\n",
    "We convert these scores into **normalized weights**:\n",
    "\n",
    "Example with only *dog* and *quickly* (assuming a score for quickly â‰ˆ 1.2):\n",
    "\n",
    "\\[\n",
    "\\alpha_{dog} = \\frac{e^{0.889}}{e^{0.889} + e^{1.2}} \\approx 0.42\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "\\alpha_{quickly} = \\frac{e^{1.2}}{e^{0.889} + e^{1.2}} \\approx 0.58\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Step 3: Combining Values\n",
    "\n",
    "The **output of \"quickly\"** is the **weighted sum of the Values**:\n",
    "\n",
    "\\[\n",
    "output(quickly) = \\alpha_{dog} \\cdot V_{dog} + \\alpha_{quickly} \\cdot V_{quickly}\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= 0.42 \\cdot [0.12, 0.84, 0.51] + 0.58 \\cdot [0.62, 0.24, 0.33]\n",
    "\\]\n",
    "\n",
    "\\[\n",
    "= [0.41, 0.49, 0.41] \\ (\\text{approx})\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Conceptual interpretation\n",
    "\n",
    "- **Each token has a single Value**, not a different one for each other token.  \n",
    "- What changes is the **weight with which that Value is combined**, according to the Queryâ€“Key similarity.  \n",
    "- The result is a **new semantic vector** for \"quickly\", which is no longer just its original embedding, but a **contextualized mixture** of information from the whole sentence.  \n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "- **Query + Key = how much attention I give to another token.**  \n",
    "- **Weights (softmax) = how strongly I listen to each token.**  \n",
    "- **Values = what each token contributes to the mix.**  \n",
    "- **Output = new contextualized vector**, used in later layers to finally **predict the next token**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434bb27",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
